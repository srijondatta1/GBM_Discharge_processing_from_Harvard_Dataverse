{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59ac86-cd0b-4722-9fde-fa7f87ce0d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ðŸ“¦ DEPENDENCIES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from hydroeval import nse, pbias, rmse\n",
    "from sklearn.metrics import r2_score\n",
    "from colorama import Fore, Style, init\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from typing import Dict, Any, List, TYPE_CHECKING\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from openpyxl.workbook import Workbook\n",
    "\n",
    "# Initialize colorama for colored console output\n",
    "init(autoreset=True)\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš™ï¸ USER CONFIGURATION (EDITABLE OPTIONS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Holds all user-configurable settings and script constants.\"\"\"\n",
    "    # --- Input / Output Paths ---\n",
    "    BASE_DIR = Path(\"Your_project_folder\")\n",
    "    OBS_DIR = BASE_DIR / \"Observed_monthly_discharge\"\n",
    "    SIM_DIR = BASE_DIR / \"Simulated_monthly_discharge\"\n",
    "    COMPARISON_DIR = BASE_DIR / \"Discharge_comparison\"\n",
    "    OUTPUT_FILE = \"Hydro_Eval_All_Subbasins.xlsx\"\n",
    "\n",
    "    # --- Time Periods for Analysis ---\n",
    "    CALIBRATION_START = \"2000-01-01\"\n",
    "    CALIBRATION_END = \"2009-12-31\"\n",
    "    VALIDATION_START = \"2010-01-01\"\n",
    "    VALIDATION_END = \"2015-12-31\"\n",
    "\n",
    "    # --- Analysis Options ---\n",
    "    # Set to False to only calculate \"Overall\" metrics. Set to True to include seasonal breakdowns.\n",
    "    RUN_SEASONAL_ANALYSIS = False\n",
    "\n",
    "    # --- Seasonal Definitions (Used only if RUN_SEASONAL_ANALYSIS is True) ---\n",
    "    SEASONS = {\n",
    "        'Wet Season': [6, 7, 8, 9, 10],         # June - October\n",
    "        'Dry Season': [11, 12, 1, 2, 3, 4, 5]    # November - May\n",
    "    }\n",
    "    \n",
    "    # To run specific subbasins, add their IDs (filename without .csv) as strings.\n",
    "    # Example: [\"Subbasin_1\", \"Subbasin_42\"]\n",
    "    # Leave empty [] to run all subbasins found in the folders.\n",
    "    SUBBASINS_TO_RUN = []\n",
    "\n",
    "    # --- Column Names in Source Files ---\n",
    "    DATE_COL = \"Year_Month\"\n",
    "    DATE_FORMAT = \"%Y_%b\"\n",
    "    OBS_COL = \"OBSERVED\"\n",
    "    SIM_COL = \"SIMULATED\"\n",
    "\n",
    "    # --- Metric Calculation Parameters ---\n",
    "    UNCERTAINTY_PERCENT = 0.5\n",
    "    STD_TYPE = 1\n",
    "    NRMSE_MODE = \"mean\"\n",
    "    KGE_VERSION = \"2009\"\n",
    "\n",
    "    # --- Report Configuration ---\n",
    "    METRICS_ORDER = [\n",
    "        \"NSE\", \"RÂ²\", \"KGE\", \"PBIAS (%)\", \"RSR\", \"RMSE\", \"MAE\", \"nRMSE (%)\",\n",
    "        \"Pearson r\", \"Pearson rÂ²\", \"MAPE (%)\", \"Bias\", \"SDR\", \"P-factor\", \"R-factor\"\n",
    "    ]\n",
    "\n",
    "# Instantiate the configuration\n",
    "cfg = Config()\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ðŸ› ï¸ HELPER & PRE-PROCESSING FUNCTIONS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def prepare_comparison_files() -> None:\n",
    "    \"\"\"\n",
    "    Merges observed and simulated data files for each subbasin from CSV files.\n",
    "    \"\"\"\n",
    "    print(Fore.CYAN + \"\\nSTEP 1: Preparing comparison files...\")\n",
    "    cfg.COMPARISON_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    obs_files = list(cfg.OBS_DIR.glob(\"*.csv\"))\n",
    "    sim_files_map = {f.stem: f for f in cfg.SIM_DIR.glob(\"*.csv\")}\n",
    "\n",
    "    if not obs_files:\n",
    "        raise FileNotFoundError(f\"No observed data files (.csv) found in {cfg.OBS_DIR}\")\n",
    "\n",
    "    for obs_path in tqdm(obs_files, desc=\"ðŸ¤ Merging Obs/Sim Files\"):\n",
    "        subbasin_id = obs_path.stem\n",
    "        if subbasin_id in sim_files_map:\n",
    "            sim_path = sim_files_map[subbasin_id]\n",
    "            try:\n",
    "                df_obs = pd.read_csv(obs_path)\n",
    "                df_sim = pd.read_csv(sim_path)\n",
    "                df_obs['Date'] = pd.to_datetime(df_obs[cfg.DATE_COL], format=cfg.DATE_FORMAT)\n",
    "                df_sim['Date'] = pd.to_datetime(df_sim[cfg.DATE_COL], format=cfg.DATE_FORMAT)\n",
    "                df_merged = pd.merge(df_obs, df_sim, on='Date', how='inner')\n",
    "                output_df = df_merged[['Date', cfg.OBS_COL, cfg.SIM_COL]].copy()\n",
    "                output_df.rename(columns={'Date': cfg.DATE_COL}, inplace=True)\n",
    "                output_df[cfg.DATE_COL] = output_df[cfg.DATE_COL].dt.strftime(cfg.DATE_FORMAT)\n",
    "                output_path = cfg.COMPARISON_DIR / f\"{subbasin_id}.csv\"\n",
    "                output_df.to_csv(output_path, index=False)\n",
    "            except Exception as e:\n",
    "                print(Fore.RED + f\"\\n  - Error processing {subbasin_id}: {e}\")\n",
    "        else:\n",
    "            print(Fore.YELLOW + f\"\\n  - Warning: No matching simulated file for {subbasin_id}\")\n",
    "\n",
    "def safe_divide(numerator: float, denominator: float, default: Any = np.nan) -> float:\n",
    "    \"\"\"\n",
    "    Performs division, returning a default value if the denominator is zero or invalid.\n",
    "    \"\"\"\n",
    "    if denominator is None or denominator == 0 or np.isnan(denominator):\n",
    "        return default\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ðŸ“Š METRIC COMPUTATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def compute_metrics(obs_series: pd.Series, sim_series: pd.Series) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Computes a comprehensive set of hydrological performance metrics.\n",
    "    \"\"\"\n",
    "    obs_arr = np.asarray(obs_series).ravel()\n",
    "    sim_arr = np.asarray(sim_series).ravel()\n",
    "    mask = ~np.isnan(obs_arr) & ~np.isnan(sim_arr)\n",
    "    obs, sim = obs_arr[mask], sim_arr[mask]\n",
    "\n",
    "    if obs.size < 2:\n",
    "        return {m: np.nan for m in cfg.METRICS_ORDER}\n",
    "\n",
    "    mean_obs, std_obs = obs.mean(), obs.std(ddof=cfg.STD_TYPE)\n",
    "    mean_sim, std_sim = sim.mean(), sim.std(ddof=cfg.STD_TYPE)\n",
    "    diff = sim - obs\n",
    "    rmse_val = np.sqrt(np.mean(diff**2))\n",
    "    pearson_r = np.corrcoef(obs, sim)[0, 1]\n",
    "    nrmse_normalizers = {\"mean\": mean_obs, \"range\": obs.max() - obs.min(), \"std\": std_obs}\n",
    "    nrmse_val = safe_divide(rmse_val, nrmse_normalizers.get(cfg.NRMSE_MODE, mean_obs)) * 100\n",
    "\n",
    "    if cfg.KGE_VERSION == \"2012\":\n",
    "        beta = safe_divide(mean_sim, mean_obs)\n",
    "        gamma = safe_divide(safe_divide(std_sim, mean_sim), safe_divide(std_obs, mean_obs))\n",
    "        kge = 1 - np.sqrt((pearson_r - 1)**2 + (beta - 1)**2 + (gamma - 1)**2)\n",
    "    else:\n",
    "        kge = 1 - np.sqrt((pearson_r - 1)**2 + (safe_divide(mean_sim, mean_obs) - 1)**2 + (safe_divide(std_sim, std_obs) - 1)**2)\n",
    "\n",
    "    delta = np.abs(sim) * cfg.UNCERTAINTY_PERCENT\n",
    "    p_factor = np.sum((obs >= (sim - delta)) & (obs <= (sim + delta))) / len(obs) if len(obs) > 0 else np.nan\n",
    "    r_factor = safe_divide(np.mean(2 * delta), std_obs)\n",
    "    mape = np.nanmean(np.abs(diff / np.where(obs == 0, np.nan, obs))) * 100\n",
    "\n",
    "    return {\n",
    "        \"NSE\": nse(sim, obs), \"RÂ²\": r2_score(obs, sim), \"Pearson r\": pearson_r,\n",
    "        \"Pearson rÂ²\": pearson_r**2, \"RSR\": safe_divide(rmse_val, std_obs),\n",
    "        \"nRMSE (%)\": nrmse_val, \"PBIAS (%)\": pbias(sim, obs), \"KGE\": kge,\n",
    "        \"RMSE\": rmse_val, \"MAE\": np.mean(np.abs(diff)), \"MAPE (%)\": mape,\n",
    "        \"Bias\": diff.mean(), \"SDR\": safe_divide(std_sim, std_obs),\n",
    "        \"P-factor\": p_factor, \"R-factor\": r_factor\n",
    "    }\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ðŸ“‘ DATA PROCESSING & EXCEL FORMATTING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def tag_season(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds 'Month' and 'Season' columns to a DataFrame based on the date.\"\"\"\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month\n",
    "    month_to_season = {m: s for s, months in cfg.SEASONS.items() for m in months}\n",
    "    df[\"Season\"] = df[\"Month\"].map(month_to_season)\n",
    "    return df\n",
    "\n",
    "def style_workbook(wb: \"Workbook\") -> None:\n",
    "    \"\"\"Applies consistent styling to all sheets in the final Excel workbook.\"\"\"\n",
    "    border = Border(left=Side(style=\"thin\"), right=Side(style=\"thin\"), top=Side(style=\"thin\"), bottom=Side(style=\"thin\"))\n",
    "    header_font = Font(bold=True)\n",
    "    center_align = Alignment(horizontal=\"center\", vertical=\"center\", wrap_text=True)\n",
    "    left_align = Alignment(horizontal=\"left\", vertical=\"center\", wrap_text=True)\n",
    "\n",
    "    for ws in wb.worksheets:\n",
    "        # Style header row (e.g., Period, Subbasin, NSE, RÂ², etc.)\n",
    "        for cell in ws[1]:\n",
    "            cell.font = header_font\n",
    "            cell.alignment = center_align\n",
    "            cell.border = border\n",
    "\n",
    "        # Style data rows\n",
    "        for row in ws.iter_rows(min_row=2):\n",
    "            for i, cell in enumerate(row):\n",
    "                cell.border = border\n",
    "                # Left-align the first two columns (Period, Subbasin index)\n",
    "                if i < 2:\n",
    "                    cell.alignment = left_align\n",
    "                # Center-align the rest (metric values)\n",
    "                else:\n",
    "                    cell.alignment = center_align\n",
    "\n",
    "        # Auto-fit all column widths\n",
    "        for col_idx in range(1, ws.max_column + 1):\n",
    "            col_letter = get_column_letter(col_idx)\n",
    "            try:\n",
    "                max_len = max(len(str(cell.value)) for cell in ws[col_letter] if cell.value)\n",
    "                ws.column_dimensions[col_letter].width = max_len + 5\n",
    "            except (ValueError, TypeError):\n",
    "                ws.column_dimensions[col_letter].width = 15\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ðŸ” MAIN EVALUATION SCRIPT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main script: prepares data, computes metrics for Cal/Val, and saves report.\n",
    "    \"\"\"\n",
    "    prepare_comparison_files()\n",
    "\n",
    "    print(Fore.CYAN + \"\\nSTEP 2: Starting Hydrological Performance Evaluation...\")\n",
    "    input_files = [f for f in cfg.COMPARISON_DIR.glob(\"*.csv\") if not f.name.startswith('~$')]\n",
    "\n",
    "    # --- Filter for specific subbasins if requested by the user ---\n",
    "    if cfg.SUBBASINS_TO_RUN:\n",
    "        print(Fore.YELLOW + f\"Filtering for specific subbasins: {cfg.SUBBASINS_TO_RUN}\")\n",
    "        input_files = [f for f in input_files if f.stem in cfg.SUBBASINS_TO_RUN]\n",
    "\n",
    "    if not input_files:\n",
    "        print(Fore.RED + f\"âš ï¸ No files to process. Check SUBBASINS_TO_RUN or the contents of: {cfg.COMPARISON_DIR}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    all_results = []\n",
    "    for file_path in tqdm(input_files, desc=\"ðŸ“Š Evaluating Subbasins\"):\n",
    "        subbasin = file_path.stem\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[cfg.OBS_COL] = pd.to_numeric(df[cfg.OBS_COL], errors='coerce')\n",
    "            df[cfg.SIM_COL] = pd.to_numeric(df[cfg.SIM_COL], errors='coerce')\n",
    "            df['Date'] = pd.to_datetime(df[cfg.DATE_COL], format=cfg.DATE_FORMAT, errors='coerce')\n",
    "            df.dropna(subset=[cfg.OBS_COL, cfg.SIM_COL, 'Date'], inplace=True)\n",
    "            df = tag_season(df)\n",
    "\n",
    "            periods = {\n",
    "                \"Calibration\": (df['Date'] >= cfg.CALIBRATION_START) & (df['Date'] <= cfg.CALIBRATION_END),\n",
    "                \"Validation\": (df['Date'] >= cfg.VALIDATION_START) & (df['Date'] <= cfg.VALIDATION_END)\n",
    "            }\n",
    "\n",
    "            for eval_period_name, date_mask in periods.items():\n",
    "                period_df = df[date_mask]\n",
    "                if period_df.empty: continue\n",
    "\n",
    "                # --- Calculate metrics for Overall and optionally Seasonal ---\n",
    "                groups = {\"Overall\": period_df}\n",
    "                if cfg.RUN_SEASONAL_ANALYSIS:\n",
    "                    groups.update({name: data for name, data in period_df.groupby(\"Season\")})\n",
    "\n",
    "                for period_name, group_df in groups.items():\n",
    "                    if group_df.empty: continue\n",
    "                    metrics = compute_metrics(group_df[cfg.OBS_COL], group_df[cfg.SIM_COL])\n",
    "                    for metric_name, value in metrics.items():\n",
    "                        all_results.append({\n",
    "                            \"EvaluationPeriod\": eval_period_name, \"Subbasin\": subbasin,\n",
    "                            \"Period\": period_name, \"Metric\": metric_name, \"Value\": value\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(Fore.RED + f\"  - Error processing {file_path.name}: {e}\")\n",
    "\n",
    "    if not all_results:\n",
    "        print(Fore.YELLOW + \"\\nNo valid data found to generate a report. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(Fore.CYAN + \"\\nSTEP 3: Generating final Excel report...\")\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    output_path = cfg.BASE_DIR / cfg.OUTPUT_FILE\n",
    "\n",
    "    try:\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            season_order = [\"Overall\"] + list(cfg.SEASONS.keys())\n",
    "\n",
    "            for eval_period in [\"Calibration\", \"Validation\"]:\n",
    "                eval_df = results_df[results_df['EvaluationPeriod'] == eval_period]\n",
    "                if eval_df.empty: continue\n",
    "\n",
    "                # --- NEW: Logic for Natural Sorting of Subbasins ---\n",
    "                unique_subbasins = eval_df['Subbasin'].unique()\n",
    "                def sort_key(subbasin_name):\n",
    "                    try:\n",
    "                        return int(subbasin_name.split('_')[-1]) # Assumes \"Name_Number\" format\n",
    "                    except (ValueError, IndexError):\n",
    "                        return subbasin_name # Fallback for other formats\n",
    "                sorted_subbasins = sorted(unique_subbasins, key=sort_key)\n",
    "                # --- End of New Sorting Logic ---\n",
    "\n",
    "                pivot = eval_df.pivot_table(\n",
    "                    index=[\"Period\", \"Subbasin\"],\n",
    "                    columns=\"Metric\",\n",
    "                    values=\"Value\"\n",
    "                )\n",
    "\n",
    "                if not pivot.empty:\n",
    "                    # Ensure columns (Metrics) are in the desired order\n",
    "                    pivot = pivot.reindex(columns=cfg.METRICS_ORDER)\n",
    "                    # Ensure the 'Period' level of the index is in the desired order\n",
    "                    pivot = pivot.reindex(level='Period', index=season_order)\n",
    "                    # --- NEW: Apply the natural sort order to the 'Subbasin' index level ---\n",
    "                    pivot = pivot.reindex(level='Subbasin', index=sorted_subbasins)\n",
    "                    pivot = pivot.round(3)\n",
    "\n",
    "                pivot.to_excel(writer, sheet_name=eval_period)\n",
    "\n",
    "            style_workbook(writer.book)\n",
    "        print(Fore.GREEN + Style.BRIGHT + f\"\\nâœ… Processing complete! Results saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(Fore.RED + f\"\\nâŒ Failed to write Excel file: {e}\")\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# â–¶ï¸ SCRIPT EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3635964-851a-4143-bb37-f4309c161a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9c572ad6-6888-4dab-a11f-ac37d961f082",
   "metadata": {},
   "source": [
    "Output preview\n",
    "\n",
    "STEP 1: Preparing comparison files...\n",
    "\n",
    "ðŸ¤ Merging Obs/Sim Files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [00:20<00:00, 20.28it/s]\n",
    "\n",
    "\n",
    "STEP 2: Starting Hydrological Performance Evaluation...\n",
    "\n",
    "ðŸ“Š Evaluating Subbasins: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [00:11<00:00, 36.95it/s]\n",
    "\n",
    "\n",
    "STEP 3: Generating final Excel report...\n",
    "\n",
    "âœ… Processing complete! Results saved to: Hydro_Eval_All_Subbasins.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a8e63-59a7-49b8-b164-191388d3576b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
