{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f6954-93ab-43fc-9467-ae79ed0b8774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#                       MONTHLY DISCHARGE DATA PROCESSOR\n",
    "# ==============================================================================\n",
    "#\n",
    "# Description:\n",
    "#   This script executes a complete data analysis workflow: loading specific\n",
    "#   columns from an Excel file, validating and transforming the data, calculating\n",
    "#   annual aggregate statistics (Min, Max, Mean) for each subbasin, and finally\n",
    "#   exporting both the detailed monthly data and the summary statistics to CSV.\n",
    "#\n",
    "# Constraints:\n",
    "#   Designed to be memory-efficient by only reading necessary columns.\n",
    "#   Suitable for datasets manageable within a 16 GB RAM environment.\n",
    "#\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#   1. DEPENDENCY IMPORTS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys # Used for clean exit after error\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#   2. USER-DEFINABLE OPTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "# Modify the variables in this section to match your file paths, column names,\n",
    "# and desired output settings.\n",
    "\n",
    "# --- I. FILE PATHS & LOCATIONS ---\n",
    "# The full path to your source Excel file.\n",
    "input_excel_path = \"Simulated_Monthly_discharge.xlsx\"\n",
    "\n",
    "# The name of the specific sheet to read. Set to None or empty string for the first sheet.\n",
    "input_sheet_name = None\n",
    "\n",
    "# The full path to the folder where the individual CSV files will be saved.\n",
    "output_directory_path = \"Simulated_monthly_discharge\"\n",
    "\n",
    "\n",
    "# --- II. DATA FILTERING & OUTPUT SETTINGS ---\n",
    "# Specify a list of subbasin IDs (as numbers or strings) to export.\n",
    "# To export ALL subbasins, set this variable to None or an empty list (e.g., []).\n",
    "# Example: subbasins_to_extract = [1, 5, 12, 18]\n",
    "subbasins_to_extract = None\n",
    "\n",
    "# The text prefix for the individual subbasin CSV files (e.g., 'Discharge_Node_1.csv').\n",
    "output_filename_prefix = 'Subbasin_'\n",
    "\n",
    "# Name for the CSV file containing the aggregated annual summary statistics.\n",
    "output_analysis_filename = 'Annual_Simulated_Discharge_Summary.csv'\n",
    "\n",
    "# Set to True to generate and export the annual summary analysis file.\n",
    "export_summary_analysis = True\n",
    "\n",
    "# NEW OPTION: Set to False to skip saving if a file with the same name already exists.\n",
    "# Set to True to always overwrite existing files.\n",
    "overwrite_existing_files = True\n",
    "\n",
    "\n",
    "# --- III. COLUMN MAPPING (Source Data) ---\n",
    "# Define the column names as they appear in your source Excel file, or what you want\n",
    "# them to be after cleaning. NOTE: The script automatically converts headers to\n",
    "# uppercase and strips whitespace for robustness.\n",
    "column_year = 'YEAR' # Maps to column YEAR\n",
    "column_month = 'MON' # Maps to column MON\n",
    "column_subbasin = 'SUB' # Maps to column SUB\n",
    "column_discharge = 'SIMULATED' # Maps to column SIMULATED\n",
    "\n",
    "\n",
    "# --- IV. COLUMN MAPPING (Output Data) ---\n",
    "# Define the names for the columns in the final exported CSV files.\n",
    "output_date_column = 'Year_Month'\n",
    "output_data_column = 'SIMULATED'\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#   3. SCRIPT EXECUTION\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- Starting Discharge Data Processing Script ---\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# List of required columns for memory-efficient loading\n",
    "# Using the defined column names here\n",
    "REQUIRED_COLS = [column_year, column_month, column_subbasin, column_discharge]\n",
    "df = pd.DataFrame() # Initialize DataFrame\n",
    "\n",
    "try:\n",
    "    # ##########################################################################\n",
    "    #   STEP 1: DATA LOADING AND VALIDATION\n",
    "    # ##########################################################################\n",
    "\n",
    "    print(\"STEP 1: DATA LOADING AND VALIDATION\\n\")\n",
    "\n",
    "    # --- Load the Source Data using only required columns ---\n",
    "    print(f\"Loading data from: '{os.path.basename(input_excel_path)}'...\")\n",
    "    \n",
    "    # Determine the sheet to read: use index 0 (first sheet) if input_sheet_name \n",
    "    # is None or empty, otherwise use the provided name/index.\n",
    "    sheet_identifier = 0 if input_sheet_name is None or input_sheet_name == \"\" else input_sheet_name\n",
    "\n",
    "    if input_sheet_name:\n",
    "        print(f\"   (Reading sheet: '{input_sheet_name}')\")\n",
    "\n",
    "    # Use 'usecols' for memory efficiency. Note: pandas reads the column names\n",
    "    # from the file and checks them against this list.\n",
    "    df = pd.read_excel(input_excel_path, sheet_name=sheet_identifier, usecols=REQUIRED_COLS)\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- Data Header Cleanup for Robustness (New Sub-Step) ---\n",
    "    # Strip whitespace and convert headers to uppercase to prevent KeyErrors\n",
    "    # caused by ' YEAR' vs 'YEAR' or 'Simulated' vs 'SIMULATED'.\n",
    "    df.columns = df.columns.str.strip().str.upper()\n",
    "    print(\"Column headers cleaned (whitespace removed, converted to uppercase).\")\n",
    "    \n",
    "    # Update column variables to match the cleaned (uppercase) DataFrame headers\n",
    "    column_year = column_year.upper()\n",
    "    column_month = column_month.upper()\n",
    "    column_subbasin = column_subbasin.upper()\n",
    "    column_discharge = column_discharge.upper()\n",
    "    \n",
    "    # --- Data Type Validation ---\n",
    "    # Ensure key columns are integers for proper merging and calculation.\n",
    "    df[column_year] = pd.to_numeric(df[column_year], errors='coerce').astype('Int64')\n",
    "    df[column_month] = pd.to_numeric(df[column_month], errors='coerce').astype('Int64')\n",
    "    df[column_subbasin] = pd.to_numeric(df[column_subbasin], errors='coerce').astype('Int64')\n",
    "    print(\"Core column data types enforced (Int64/numeric).\")\n",
    "\n",
    "    # --- Data Filtering by Subbasin (if configured) ---\n",
    "    if subbasins_to_extract and len(subbasins_to_extract) > 0:\n",
    "        original_rows = len(df)\n",
    "        df = df[df[column_subbasin].isin(subbasins_to_extract)]\n",
    "        filtered_rows = len(df)\n",
    "        print(f\"Data filtered: Retained {filtered_rows} rows for {len(subbasins_to_extract)} specified subbasins (removed {original_rows - filtered_rows} rows).\")\n",
    "    else:\n",
    "        print(\"No subbasin filter applied (processing all available subbasins).\")\n",
    "\n",
    "\n",
    "    # ##########################################################################\n",
    "    #   STEP 2: DATA TRANSFORMATION\n",
    "    # ##########################################################################\n",
    "\n",
    "    print(\"\\nSTEP 2: DATA TRANSFORMATION\\n\")\n",
    "\n",
    "    # --- Creating a month mapping dictionary ---\n",
    "    month_map = {\n",
    "        1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "        7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "    }\n",
    "\n",
    "    # --- Constructing the combined date column ---\n",
    "    # Combines the year and month into a readable format (e.g., '1995_Dec').\n",
    "    df[output_date_column] = df[column_year].astype(str) + '_' + df[column_month].map(month_map)\n",
    "    print(f\"'{output_date_column}' column created successfully.\")\n",
    "\n",
    "\n",
    "    # ##########################################################################\n",
    "    #   STEP 3: COMPREHENSIVE DATA ANALYSIS (AGGREGATION)\n",
    "    # ##########################################################################\n",
    "\n",
    "    print(\"\\nSTEP 3: COMPREHENSIVE DATA ANALYSIS (AGGREGATION)\\n\")\n",
    "\n",
    "    # --- Calculating Annual Summary Statistics ---\n",
    "    # Group by both Year and Subbasin to find annual statistics.\n",
    "    # Rationale: This calculation provides a high-level overview of hydrologic\n",
    "    # variability, summarizing the discharge characteristics (min, max, mean)\n",
    "    # for each subbasin within a single calendar year.\n",
    "    if export_summary_analysis:\n",
    "        analysis_df = df.groupby([column_subbasin, column_year])[column_discharge].agg(\n",
    "            Annual_Mean_Discharge='mean',\n",
    "            Annual_Min_Discharge='min',\n",
    "            Annual_Max_Discharge='max',\n",
    "            Monthly_Count='count'\n",
    "        ).reset_index()\n",
    "\n",
    "        # Display the result logic\n",
    "        print(f\"Annual summary statistics calculated for {len(analysis_df)} Subbasin-Year combinations.\")\n",
    "        print(f\"Head of summary data:\\n{analysis_df.head(5).to_string()}\")\n",
    "\n",
    "\n",
    "    # ##########################################################################\n",
    "    #   STEP 4: EXPORTING DATA ARTIFACTS\n",
    "    # ##########################################################################\n",
    "\n",
    "    print(\"\\nSTEP 4: EXPORTING DATA ARTIFACTS\\n\")\n",
    "\n",
    "    # --- Ensure the output directory exists ---\n",
    "    os.makedirs(output_directory_path, exist_ok=True)\n",
    "    print(f\"Output directory confirmed: '{output_directory_path}'\")\n",
    "\n",
    "    # --- Sub-step 4a: Exporting Aggregated Analysis (if enabled) ---\n",
    "    if export_summary_analysis:\n",
    "        output_path = os.path.join(output_directory_path, output_analysis_filename)\n",
    "        \n",
    "        # Check overwrite for summary file\n",
    "        if not overwrite_existing_files and os.path.exists(output_path):\n",
    "             print(f\"[SKIP] Summary file already exists and overwrite is False: {output_analysis_filename}\")\n",
    "        else:\n",
    "            analysis_df.to_csv(output_path, index=False)\n",
    "            print(f\"Annual Summary Analysis exported to: '{output_analysis_filename}'\")\n",
    "\n",
    "\n",
    "    # --- Sub-step 4b: Exporting Detailed Monthly Data per Subbasin ---\n",
    "    grouped_by_subbasin = df.groupby(column_subbasin)\n",
    "    number_of_subbasins = len(grouped_by_subbasin)\n",
    "\n",
    "    if number_of_subbasins == 0:\n",
    "        print(\"\\n[WARNING] No data remains for export (check filters or input data).\")\n",
    "    else:\n",
    "        print(f\"\\nPreparing to export {number_of_subbasins} individual subbasin files...\")\n",
    "\n",
    "        # Iterating and saving files with a progress bar\n",
    "        for subbasin_id, subbasin_df in tqdm(grouped_by_subbasin, total=number_of_subbasins, desc=\"Subbasins Processed\"):\n",
    "\n",
    "            # Selecting and renaming columns for final output\n",
    "            output_df = subbasin_df[[output_date_column, column_discharge]].rename(\n",
    "                columns={column_discharge: output_data_column}\n",
    "            )\n",
    "\n",
    "            # Defining the output file path using the user-defined prefix\n",
    "            output_filename = os.path.join(output_directory_path, f\"{output_filename_prefix}{subbasin_id}.csv\")\n",
    "            \n",
    "            # --- Check and Overwrite Logic ---\n",
    "            if not overwrite_existing_files and os.path.exists(output_filename):\n",
    "                # Using tqdm.write() to ensure the message is printed correctly alongside the progress bar\n",
    "                tqdm.write(f\"[SKIP] File already exists and overwrite is set to False: {os.path.basename(output_filename)}\")\n",
    "                continue\n",
    "\n",
    "            # Saving the DataFrame to a CSV file\n",
    "            output_df.to_csv(output_filename, index=False)\n",
    "\n",
    "        print(\"\\nDetailed data export process completed.\")\n",
    "\n",
    "\n",
    "    # ##########################################################################\n",
    "    #   STEP 5: FINAL REPORTING\n",
    "    # ##########################################################################\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 5: FINAL REPORTING\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(f\"Total Subbasins Processed: {number_of_subbasins}\")\n",
    "    print(f\"Total Monthly Records Retained: {len(df)}\")\n",
    "    print(f\"Output Directory: {output_directory_path}\")\n",
    "    print(f\"Overwrite Files Enabled: {overwrite_existing_files}\")\n",
    "    \n",
    "    print(\"\\nScript execution successful.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n[ERROR] The input file could not be found at the specified path:\")\n",
    "    print(f\"        '{input_excel_path}'\")\n",
    "    print(\"        Please check the path in Section 2 (I. FILE PATHS) and try again.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "except KeyError as e:\n",
    "    # This error should now only occur if the column name doesn't exist *even* after\n",
    "    # stripping and uppercasing (e.g., if the user typo'd the input column mapping)\n",
    "    print(f\"\\n[ERROR] A required column was not found in the Excel file: {e}\")\n",
    "    print(f\"        Please verify the column mappings in Section 2 (III. COLUMN MAPPING (Source Data)).\")\n",
    "    print(f\"        The script expected the uppercase column name as defined in the user options.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[CRITICAL ERROR] An unexpected error occurred: {e}\")\n",
    "    print(\"        Execution halted. Please review the error message to diagnose the issue.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "finally:\n",
    "    print(\"\\n--- Script has finished execution. ---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb901e-fbd1-4e35-99e6-e6ca9cc48afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f51daf70-73b0-485b-806c-f1dd4bc42db9",
   "metadata": {},
   "source": [
    "Output preview\n",
    "\n",
    "==================================================\n",
    "--- Starting Discharge Data Processing Script ---\n",
    "==================================================\n",
    "\n",
    "STEP 1: DATA LOADING AND VALIDATION\n",
    "\n",
    "Loading data from: 'Simulated_Monthly_discharge.xlsx'...\n",
    "Data loaded successfully.\n",
    "Column headers cleaned (whitespace removed, converted to uppercase).\n",
    "Core column data types enforced (Int64/numeric).\n",
    "No subbasin filter applied (processing all available subbasins).\n",
    "\n",
    "STEP 2: DATA TRANSFORMATION\n",
    "\n",
    "'Year_Month' column created successfully.\n",
    "\n",
    "STEP 3: COMPREHENSIVE DATA ANALYSIS (AGGREGATION)\n",
    "\n",
    "Annual summary statistics calculated for 12450 Subbasin-Year combinations.\n",
    "Head of summary data:\n",
    "   SUB  YEAR  Annual_Mean_Discharge  Annual_Min_Discharge  Annual_Max_Discharge  Monthly_Count\n",
    "0    1  1991            1499.450000                170.90                4791.0             12\n",
    "1    1  1992             688.281667                 87.05                2200.0             12\n",
    "2    1  1993            1282.025833                 98.01                4047.0             12\n",
    "3    1  1994             695.942500                 10.72                2288.0             12\n",
    "4    1  1995            1201.395833                 30.95                3579.0             12\n",
    "\n",
    "STEP 4: EXPORTING DATA ARTIFACTS\n",
    "\n",
    "Output directory confirmed: 'Simulated_monthly_discharge'\n",
    "Annual Summary Analysis exported to: 'Annual_Discharge_Summary.csv'\n",
    "\n",
    "Preparing to export 415 individual subbasin files...\n",
    "\n",
    "Subbasins Processed: 100%|██████████████████████████████████████████████████████████| 415/415 [00:01<00:00, 258.90it/s]\n",
    "\n",
    "\n",
    "Detailed data export process completed.\n",
    "\n",
    "==================================================\n",
    "STEP 5: FINAL REPORTING\n",
    "==================================================\n",
    "\n",
    "Total Subbasins Processed: 415\n",
    "Total Monthly Records Retained: 149400\n",
    "Output Directory: Simulated_monthly_discharge\n",
    "Overwrite Files Enabled: True\n",
    "\n",
    "Script execution successful.\n",
    "\n",
    "--- Script has finished execution. ---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
