{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadb665-4113-4590-a6e5-fb1364dcb9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#                  MONTHLY OBSERVED DISCHARGE DATA PROCESSOR\n",
    "# ==============================================================================\n",
    "#\n",
    "# Description:\n",
    "#   This script reads a directory of CSV files containing daily observed\n",
    "#   discharge data for multiple subbasins. It aggregates the daily data into\n",
    "#   a monthly format based on a user-defined calculation (e.g., mean, sum),\n",
    "#   creates a 'Year_Month' column, and exports the processed data for each\n",
    "#   subbasin into a corresponding CSV file in a new directory.\n",
    "#\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#   1. DEPENDENCY IMPORTS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#   2. USER-DEFINABLE OPTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "# Modify the variables in this section to control the script's behavior.\n",
    "\n",
    "# --- File and Directory Paths ---\n",
    "input_directory_path = \"Observed_daily_dscharge/Raw_netcdf/02_Final_Merged_Streamflow\"\n",
    "output_directory_path = \"Observed_monthly_discharge\"\n",
    "\n",
    "# --- Input File and Column Names ---\n",
    "# The pattern to find input files. \"*.csv\" finds all CSVs.\n",
    "# You could change this to \"Subbasin_*.csv\" to only find files starting with \"Subbasin_\".\n",
    "input_file_pattern = \"*.csv\"\n",
    "\n",
    "# The exact name of the column in your source files that contains the date.\n",
    "source_date_column = \"DATE\"\n",
    "\n",
    "# The exact name of the column in your source files that contains the discharge data.\n",
    "source_data_column = \"DISCHARGE\"\n",
    "\n",
    "# --- Output Formatting and Calculation ---\n",
    "# The name you want for the data column in the final output files.\n",
    "output_data_column_name = \"OBSERVED\"\n",
    "\n",
    "# The format for the 'Year_Month' column.\n",
    "#   - '%Y_%b'  ->  '1995_Dec'\n",
    "#   - '%Y-%m'  ->  '1995-12'\n",
    "#   - '%b-%Y'  ->  'Dec-1995'\n",
    "output_date_format = '%Y_%b'\n",
    "\n",
    "# The method for aggregating daily data to monthly.\n",
    "# Common options (must be in quotes): 'mean', 'sum', 'median', 'min', 'max'\n",
    "aggregation_method = 'mean'\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#   3. SCRIPT EXECUTION\n",
    "# ------------------------------------------------------------------------------\n",
    "# Do not modify the code below unless you intend to change the script's logic.\n",
    "\n",
    "print(\"\\n--- Starting Observed Daily Discharge Processing Script ---\")\n",
    "\n",
    "try:\n",
    "    # --- Step A: Locate Input Files ---\n",
    "\n",
    "    print(f\"\\nSearching for '{input_file_pattern}' files in: '{input_directory_path}'...\")\n",
    "    search_pattern = os.path.join(input_directory_path, input_file_pattern)\n",
    "    csv_files = glob.glob(search_pattern)\n",
    "\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No files matching the pattern '{input_file_pattern}' were found in the specified input directory.\")\n",
    "\n",
    "    print(f\"Found {len(csv_files)} files to process.\")\n",
    "\n",
    "\n",
    "    # --- Step B: Ensure Output Directory Exists ---\n",
    "\n",
    "    print(f\"\\nEnsuring output directory exists at: '{output_directory_path}'\")\n",
    "    os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    # --- Step C: Process Each CSV File ---\n",
    "\n",
    "    print(f\"\\nProcessing and exporting files using '{aggregation_method}' aggregation...\")\n",
    "    for file_path in tqdm(csv_files, total=len(csv_files), desc=\"Files Processed\"):\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # --- Loading the daily data ---\n",
    "        daily_df = pd.read_csv(file_path, parse_dates=[source_date_column])\n",
    "\n",
    "\n",
    "        # --- Aggregating daily data to monthly ---\n",
    "        daily_df.set_index(source_date_column, inplace=True)\n",
    "\n",
    "        # Dynamically apply the user-specified aggregation method\n",
    "        # Using 'ME' for month-end frequency to align with modern pandas versions.\n",
    "        resampled_data = daily_df[source_data_column].resample('ME')\n",
    "        monthly_aggregated_series = getattr(resampled_data, aggregation_method)()\n",
    "\n",
    "        monthly_df = monthly_aggregated_series.reset_index()\n",
    "\n",
    "\n",
    "        # --- Formatting the output DataFrame ---\n",
    "        monthly_df.rename(columns={source_data_column: output_data_column_name}, inplace=True)\n",
    "        monthly_df['Year_Month'] = monthly_df[source_date_column].dt.strftime(output_date_format)\n",
    "\n",
    "\n",
    "        # --- Saving the processed data ---\n",
    "        output_df = monthly_df[['Year_Month', output_data_column_name]]\n",
    "        output_filename = os.path.join(output_directory_path, file_name)\n",
    "        output_df.to_csv(output_filename, index=False)\n",
    "\n",
    "\n",
    "    print(\"\\nExport process completed successfully.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n[ERROR] {e}\")\n",
    "    print(\"        Please check the path and pattern in the 'USER-DEFINABLE OPTIONS' section and try again.\")\n",
    "except AttributeError:\n",
    "    print(f\"\\n[ERROR] Invalid 'aggregation_method': '{aggregation_method}'.\")\n",
    "    print(\"        Please choose a valid pandas resampling method like 'mean', 'sum', 'median', 'min', or 'max'.\")\n",
    "except KeyError as e:\n",
    "    print(f\"\\n[ERROR] A column was not found: {e}.\")\n",
    "    print(\"        Please ensure 'source_date_column' and 'source_data_column' are set correctly in the options.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] An unexpected error occurred: {e}\")\n",
    "    print(\"        Please review the error message to diagnose the issue.\")\n",
    "\n",
    "\n",
    "finally:\n",
    "    print(\"\\n--- Script has finished execution. ---\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f10e22-b797-421a-8228-cf035accb3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e9be567b-e8a6-4a07-b36a-545563ab2fc4",
   "metadata": {},
   "source": [
    "Output preview\n",
    "\n",
    "--- Starting Observed Daily Discharge Processing Script ---\n",
    "\n",
    "Searching for '*.csv' files in: 'Observed_daily_dscharge/Raw_netcdf/02_Final_Merged_Streamflow'...\n",
    "Found 415 files to process.\n",
    "\n",
    "Ensuring output directory exists at: 'Observed_monthly_discharge'\n",
    "\n",
    "Processing and exporting files using 'mean' aggregation...\n",
    "\n",
    "Files Processed: 100%|███████████████████████████████████████████████████████████████| 415/415 [00:36<00:00, 11.28it/s]\n",
    "\n",
    "\n",
    "Export process completed successfully.\n",
    "\n",
    "--- Script has finished execution. ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125d1b2-93f9-45a4-8c90-3dcf693ca039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
